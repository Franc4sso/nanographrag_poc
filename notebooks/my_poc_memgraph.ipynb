{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d9285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nano-graphrag:Loading tokenizer: type='tiktoken', name='gpt-3.5'\n",
      "INFO:nano-graphrag:Load KV full_docs with 1 data\n",
      "INFO:nano-graphrag:Load KV text_chunks with 1 data\n",
      "INFO:nano-graphrag:Load KV llm_response_cache with 4 data\n",
      "INFO:nano-graphrag:Load KV community_reports with 2 data\n",
      "INFO:nano-graphrag:Loaded graph from ./nano_cache\\graph_chunk_entity_relation.graphml with 8 nodes, 12 edges\n",
      "INFO:nano-vectordb:Load (8, 1536) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': './nano_cache\\\\vdb_entities.json'} 8 data\n",
      "WARNING:nano-graphrag:All docs are already in the storage\n",
      "INFO:nano-graphrag:Writing graph with 8 nodes, 12 edges\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Triplette estratte:\n",
      "\"LA FRANCIA\" --[\"La Francia and Il Regno Unito formed an alliance during World War II to combat shared enemies.\"]--> \"IL REGNO UNITO\"\n",
      "\"LA FRANCIA\" --[\"La Francia and Gli Stati Uniti were allies during World War II.\"]--> \"GLI STATI UNITI\"\n",
      "\"LA FRANCIA\" --[\"La Francia was part of Le forze alleate working together against the Axis powers.\"]--> \"LE FORZE ALLEATE\"\n",
      "\"IL REGNO UNITO\" --[\"Il Regno Unito and Gli Stati Uniti were allies, collaborating during World War II.\"]--> \"GLI STATI UNITI\"\n",
      "\"IL REGNO UNITO\" --[\"Il Regno Unito was part of Le forze alleate, collaborating with other Allied countries during World War II.\"]--> \"LE FORZE ALLEATE\"\n",
      "\"LA SECONDA GUERRA MONDIALE\" --[\"La Germania was a major opposing force to the Allies during World War II.\"]--> \"LA GERMANIA\"\n",
      "\"LA SECONDA GUERRA MONDIALE\" --[\"L'Unione Sovietica played a key role in the Allies' victory over Nazi Germany in World War II.\"]--> \"L'UNIONE SOVIETICA\"\n",
      "\"GLI STATI UNITI\" --[\"Gli Stati Uniti were members of Le forze alleate, contributing to the collective efforts in World War II.\"]--> \"LE FORZE ALLEATE\"\n",
      "\"LA GERMANIA\" --[\"L'Unione Sovietica combated against Nazi Germany as part of the Allied forces.\"]--> \"L'UNIONE SOVIETICA\"\n",
      "\"LA GERMANIA\" --[\"Le forze alleate opposed La Germania during World War II, combating its military aggression across Europe.\"]--> \"LE FORZE ALLEATE\"\n",
      "\"L'UNIONE SOVIETICA\" --[\"L'Unione Sovietica joined Le forze alleate to fight against Nazi Germany and its allies during World War II.\"]--> \"LE FORZE ALLEATE\"\n",
      "\"LE FORZE ALLEATE\" --[\"Le forze alleate fought against the military forces of La Germania nazista during World War II.\"]--> \"LA GERMANIA NAZISTA\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from nano_graphrag import GraphRAG\n",
    "import networkx as nx\n",
    "\n",
    "# âœ… STEP 1 â€“ Carica il testo da un file\n",
    "with open(\"data/alleanze.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# âœ… STEP 2 â€“ Imposta la tua chiave API OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_api_key\"  # Sostituisci con la tua chiave reale\n",
    "\n",
    "# âœ… STEP 3 â€“ Inizializza GraphRAG\n",
    "graphrag = GraphRAG(\n",
    "    working_dir=\"./nano_cache\",\n",
    "    enable_local=True,\n",
    "    tokenizer_type=\"tiktoken\",\n",
    "    tiktoken_model_name=\"gpt-3.5\",  # usa gpt-4o solo se abilitato nel tuo account\n",
    "    graph_cluster_algorithm=None  # evitiamo errore sul clustering\n",
    ")\n",
    "\n",
    "# âœ… STEP 4 â€“ Inserisci il documento (solo in ambienti Jupyter: usa `await`)\n",
    "await graphrag.ainsert(text)\n",
    "\n",
    "# âœ… STEP 5 â€“ Carica il grafo salvato da file\n",
    "G = nx.read_graphml(\"./nano_cache/graph_chunk_entity_relation.graphml\")\n",
    "\n",
    "# âœ… STEP 6 â€“ Stampa le triplette soggetto --[relazione]--> oggetto\n",
    "print(\"\\nðŸ“Œ Triplette estratte:\")\n",
    "for u, v, data in G.edges(data=True):\n",
    "    relation = data.get(\"description\", \"(nessuna relazione)\")\n",
    "    print(f\"{u} --[{relation}]--> {v}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be1e73b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mgclient'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmgclient\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# âœ… Carica grafo da GraphML generato da GraphRAG\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mgclient'"
     ]
    }
   ],
   "source": [
    "import mgclient\n",
    "import networkx as nx\n",
    "\n",
    "# âœ… Carica grafo da GraphML generato da GraphRAG\n",
    "G = nx.read_graphml(\"./nano_cache/graph_chunk_entity_relation.graphml\")\n",
    "\n",
    "# âœ… Estrai le triplette (soggetto, relazione, oggetto)\n",
    "triples = []\n",
    "for u, v, data in G.edges(data=True):\n",
    "    subject = u.replace('\"', '')  # rimuove virgolette doppie\n",
    "    obj = v.replace('\"', '')\n",
    "    relation = data.get(\"description\", \"relazione_non_specificata\").replace('\"', '')\n",
    "    triples.append((subject, relation, obj))\n",
    "\n",
    "# âœ… Connessione a Memgraph\n",
    "conn = mgclient.connect(host=\"localhost\", port=7687)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# âœ… Inserimento delle triplette in Memgraph\n",
    "for s, r, o in triples:\n",
    "    cursor.execute(\"\"\"\n",
    "        MERGE (a:Entity {name: $s})\n",
    "        MERGE (b:Entity {name: $o})\n",
    "        MERGE (a)-[:RELATION {description: $r}]->(b)\n",
    "    \"\"\", {\"s\": s, \"o\": o, \"r\": r})\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"âœ… Triplette inserite in Memgraph.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"MATCH (a)-[r]->(b) RETURN a.name, r.type, b.name\")\n",
    "for row in cursor:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c348c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "  MATCH (a)-[r]->(b) \n",
    "  RETURN a.name, r.type, b.name\n",
    "\"\"\")\n",
    "\n",
    "context = \"\\n\".join([f\"{a} {r} {b}\" for a, r, b in cursor])\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Rispondi solo in base al contesto fornito.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Contesto:\\n{context}\\n\\nDomanda: Quali alleanze ha stretto la Francia?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(\"Risposta LLM:\")\n",
    "print(response['choices'][0]['message']['content'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
